version: "3.7"

services:
  # This service runs the postgres DB used by dagster for run storage, schedule storage,
  # and event log storage.
  dagster_postgresql:
    image: postgres:11
    container_name: dagster_postgresql
    environment:
      POSTGRES_USER: "${DAGSTER_POSTGRES_USER}"
      POSTGRES_PASSWORD: "${DAGSTER_POSTGRES_PASSWORD}"
      POSTGRES_DB: "${DAGSTER_POSTGRES_DB}"
    networks:
      - dagster_network

  # This service runs the postgis DB used to publish datasets, either via GeoServer or REST services,
  # and to perform data transformation
  ipl_postgis:
    image: postgis/postgis:${IPL_POSTGIS_VERSION_TAG}
    container_name: ipl_postgis
    volumes:
      - ./geo-db-data:/var/lib/postgresql
    ports:
      - ${IPL_POSTGRES_PORT}:5432
    restart: on-failure
    healthcheck:
      test: "PGPASSWORD=${IPL_POSTGRES_PASSWORD} pg_isready -h 127.0.0.1 -U ${IPL_POSTGRES_USER} -d ${IPL_POSTGRES_DB}"
    environment:
      POSTGRES_USER: "${IPL_POSTGRES_USER}"
      POSTGRES_PASSWORD: "${IPL_POSTGRES_PASSWORD}"
      POSTGRES_DB: "${IPL_POSTGRES_DB}"
    networks:
      - dagster_network

  # This service runs the gRPC server that loads your user code, in both dagster-webserver
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by 
  # dagster-webserver.
  dagster_pipeline:
    build:
      context: .
      dockerfile: ./pipeline.Dockerfile
    container_name: dagster_pipeline
    image: "${DAGSTER_CURRENT_IMAGE}"
    restart: always
    environment:
      - DAGSTER_POSTGRES_USER
      - DAGSTER_POSTGRES_PASSWORD
      - DAGSTER_POSTGRES_DB
      - IPL_LAMASSU_BASE_URL
      - IPL_POSTGRES_HOST
      - IPL_POSTGRES_USER
      - IPL_POSTGRES_PASSWORD
      - IPL_POSTGRES_DB
      - IPL_POSTGRES_PORT
    networks:
      - dagster_network

  # This service runs dagster-webserver (dagit), which loads your user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from dagster-webserver
  # will be put on a queue and later dequeued and launched by dagster-daemon.
  dagster_dagit:
    build:
      context: .
      dockerfile: ./dagster.Dockerfile
      target: dagit
    container_name: dagster_dagit
    ports:
      - "3000:3000"
    environment:
      - DAGSTER_POSTGRES_USER
      - DAGSTER_POSTGRES_PASSWORD
      - DAGSTER_POSTGRES_DB
    volumes:
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      - dagster_network
    depends_on:
      - dagster_postgresql
      - dagster_pipeline

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemon:
    build:
      context: .
      dockerfile: ./dagster.Dockerfile
      target: daemon
    container_name: dagster_daemon
    restart: on-failure
    environment:
      - DAGSTER_POSTGRES_USER
      - DAGSTER_POSTGRES_PASSWORD
      - DAGSTER_POSTGRES_DB
    volumes:
      - /tmp/io_manager_storage:/tmp/io_manager_storage
    networks:
      - dagster_network
    depends_on:
      - dagster_postgresql
      - dagster_pipeline

networks:
  dagster_network:
    driver: bridge
    name: dagster_network
